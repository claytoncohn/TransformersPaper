# TransformersPaper
This repo is created by Clayton Cohn for Vanderbilt University's _DS5899 — Special Topics in Data Science: Transformers_ class paper presentation. Links are provided in-line.

## Overview (Video)

Overview and critical analysis [video](https://youtu.be/mp2d08ZDRL8).

## Presentation Matials

PowerPoint presentation found [here](https://github.com/claytoncohn/TransformersPaper/blob/main/Overview.pptx).

## Question 1

BERT (and BERT-based models) is largely considered SOTA for many NLU tasks, but do you see any problems (other than the ones I've mentioned) with using BERT and other Transformer models in practice? 

## Question 2

For my research, I am working on building a pedagogical, multimodal, conversational AI agent for collaborative learning environments. Do you have any ideas for an architecture, using BERT or other Transformer models, that might be conducive to this type of task?

## Code Demonstration

[Tagging Scientific Concepts for Automated Formative Assessment Evaluation w/ BERT](https://github.com/claytoncohn/TransformersPaper/blob/main/StudentEssaysConceptTagging.ipynb)

## Resource Links

[BERT Explained](https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c)

[Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)

[Illustrated BERT](https://jalammar.github.io/illustrated-bert/)

[BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)

[Tagging Genes and Proteins with BioBERT](https://towardsdatascience.com/tagging-genes-and-proteins-with-biobert-c7b04fc6eb4f)

[BERT parameters broken down](https://stackoverflow.com/questions/64485777/how-is-the-number-of-parameters-be-calculated-in-bert-model)

## References

<a id="1">[0]</a>
[Mikolov, T., Chen, K., Corrado, G., and Dean, J., “Efficient Estimation of Word Representations in Vector Space”, <i>arXiv e-prints</i>, 2013.](https://arxiv.org/abs/1301.3781)

<a id="1">[1]</a>
[Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. "Glove: Global vectors for word representation." <i>Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</i>. 2014.](https://aclanthology.org/D14-1162.pdf)

<a id="1">[2]</a> 
[Vaswani, A., “Attention Is All You Need”, <i>arXiv e-prints</i>, 2017.](https://arxiv.org/abs/1706.03762)

<a id="1">[3]</a>
[Peters, M. E., “Deep contextualized word representations”, <i>arXiv e-prints</i>, 2018.](https://arxiv.org/abs/1802.05365)

<a id="1">[4]</a> 
[Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models are unsupervised multitask learners. <i>OpenAI blog, 1</i>(8), 9.](https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf)

<a id="1">[5]</a> 
[Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K., “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”, <i>arXiv e-prints</i>, 2018.](https://arxiv.org/abs/1810.04805)

<a id="1">[6]</a> 
[Liu, Y., “RoBERTa: A Robustly Optimized BERT Pretraining Approach”, <i>arXiv e-prints</i>, 2019.](https://arxiv.org/abs/1907.11692)

<a id="1">[7]</a> 
[EchoCache, and Chandan. <i>“How Is the Number of Parameters Be Calculated in Bert Model?”</i> How Is the Number of Parameters Be Calculated in BERT Model?, Stack Overflow, 22 Oct. 2020, https://stackoverflow.com/questions/64485777/how-is-the-number-of-parameters-be-calculated-in-bert-model.](https://stackoverflow.com/questions/64485777/how-is-the-number-of-parameters-be-calculated-in-bert-model)

<a id="1">[8]</a> 
[McCormick, Chris, and Nick Ryan. <“BERT Fine-Tuning Tutorial with PyTorch.” <i>BERT Fine-Tuning Tutorial with PyTorch · Chris McCormick</i>, Chris McCormick, 22 July 2019, https://mccormickml.com/2019/07/22/BERT-fine-tuning/.](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)

<a id="1">[9]</a> 
[Perkins, Drew. “Tagging Genes and Proteins with BioBERT.” <i>Medium</i>, Towards Data Science, 27 Aug. 2020, https://towardsdatascience.com/tagging-genes-and-proteins-with-biobert-c7b04fc6eb4f.](https://towardsdatascience.com/tagging-genes-and-proteins-with-biobert-c7b04fc6eb4f)

# QUESTIONS?
